{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c32dcdba",
   "metadata": {},
   "source": [
    "Lecturer: Nguyen Thon Da Ph.D\n",
    "Course: Big Data\n",
    "Content: Working with Spark\n",
    "\n",
    "Team 2:\n",
    "1. Nguyen Ngoc Binh - K204141907\n",
    "2. Huynh Chi Dung - K204140638\n",
    "3. Ngo Hai Minh - K204140639\n",
    "4. Nguyen Thi Thuy Trang - K204141934"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dee4b91",
   "metadata": {},
   "source": [
    "# Reading Data from a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "a1709d25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /home/user/anaconda3/lib/python3.11/site-packages (3.5.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /home/user/anaconda3/lib/python3.11/site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "8ecbefe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |--   Price  : string (nullable = true)\n",
      " |--   Open  : string (nullable = true)\n",
      " |--   High  : string (nullable = true)\n",
      " |--   Low  : string (nullable = true)\n",
      " |--   Vol  : string (nullable = true)\n",
      " |-- Change: string (nullable = true)\n",
      " |-- direction: string (nullable = true)\n",
      " |-- mavg: string (nullable = true)\n",
      "\n",
      "[('Date', 'string'), ('  Price  ', 'string'), ('  Open  ', 'string'), ('  High  ', 'string'), ('  Low  ', 'string'), ('  Vol  ', 'string'), ('Change', 'string'), ('direction', 'string'), ('mavg', 'string')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 327:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"PySpark Basics\").getOrCreate()\n",
    "\n",
    "# Define file location and read options\n",
    "file_location = \"NVL Historical Data.csv\"\n",
    "file_type = \"csv\"\n",
    "infer_schema = \"False\"\n",
    "first_row_is_header = \"True\"\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = spark.read.format(file_type) \\\n",
    "    .option(\"inferSchema\", infer_schema) \\\n",
    "    .option(\"header\", first_row_is_header) \\\n",
    "    .load(file_location)\n",
    "\n",
    "# Print the DataFrame schema, data types, and record count\n",
    "df.printSchema()\n",
    "print(df.dtypes)\n",
    "print(df.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832bad67",
   "metadata": {},
   "source": [
    "# Subset Columns and View a Glimpse of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "9497981d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+-----+------+----------+-----------+\n",
      "|      Date|Price| Open| High|  Low|  Vol|Change| direction|       mavg|\n",
      "+----------+-----+-----+-----+-----+-----+------+----------+-----------+\n",
      "|2023-09-29|15550|15800|16150|15550|12.38| -0.01|Decreasing|      15600|\n",
      "|2023-09-28|15750|15500|16050|15300|20.77|  0.02|Increasing|      15675|\n",
      "|2023-09-27|15500|15250|15500|14500| 30.5|  0.02|Increasing|15616.66667|\n",
      "|2023-09-26|15150|15800|16500|15150|33.77| -0.06|Decreasing|      15500|\n",
      "|2023-09-25|16200|17200|17600|16200|28.12| -0.07|Decreasing|      15640|\n",
      "|2023-09-22|17400|17700|17800|16950|36.48| -0.04|Decreasing|15933.33333|\n",
      "|2023-09-21|18200|18750|19150|18000|30.13| -0.02|Decreasing|16257.14286|\n",
      "|2023-09-20|18500|17200|18500|16600|40.16|  0.07|Increasing|    16537.5|\n",
      "|2023-09-19|17300|18250|18450|17050|54.72| -0.05|Decreasing|      16750|\n",
      "|2023-09-18|18150|18900|18900|18050|28.32| -0.04|Decreasing|      17050|\n",
      "|2023-09-15|18900|19000|19250|18650|26.73|  0.01|Increasing|      17475|\n",
      "|2023-09-14|18700|19600|19800|18600|76.98| -0.06|Decreasing|   17918.75|\n",
      "|2023-09-13|19950|21000|21100|19500|77.13| -0.05|Decreasing|    18387.5|\n",
      "|2023-09-12|20950|20150|20950|19650|57.21|  0.02|Increasing|   18831.25|\n",
      "|2023-09-11|20500|22050|22200|20500|71.69| -0.07|Decreasing|   19118.75|\n",
      "|2023-09-08|22000|21600|22250|21400|52.61|  0.02|Increasing|   19556.25|\n",
      "|2023-09-07|21600|22000|22150|21500|44.46| -0.01|Decreasing|   20093.75|\n",
      "|2023-09-06|21800|21300|21800|21000|46.22|  0.02|Increasing|      20550|\n",
      "|2023-09-05|21400|20900|21700|20800|53.91|  0.05|Increasing|    20862.5|\n",
      "|2023-08-31|20450|20100|20500|20000|36.64|  0.02|Increasing|   21081.25|\n",
      "|2023-08-30|20050|20500|20600|19500|67.19| -0.01|Decreasing|   21093.75|\n",
      "|2023-08-29|20350|20200|21050|20100|40.37|  0.02|Increasing|   21018.75|\n",
      "|2023-08-28|20000|19600|20100|19350|33.67|  0.03|Increasing|   20956.25|\n",
      "|2023-08-25|19400|19800|20000|19300|33.52| -0.02|Decreasing|   20631.25|\n",
      "|2023-08-24|19800|18800|19950|18550| 40.9|  0.06|Increasing|   20406.25|\n",
      "|2023-08-23|18700|18800|19250|18550| 29.6|  0.01|Increasing|   20018.75|\n",
      "|2023-08-22|18500|18550|18900|17300|45.88|     0|Decreasing|   19656.25|\n",
      "|2023-08-21|18500|18800|19100|18050|46.79| -0.04|Decreasing|    19412.5|\n",
      "|2023-08-18|19250|20450|20500|19250|73.13| -0.07|Decreasing|    19312.5|\n",
      "|2023-08-17|20650|20500|21150|20500|40.74|     0|Decreasing|      19350|\n",
      "|2023-08-16|20650|20650|20900|20300|40.99|     0|Decreasing|   19431.25|\n",
      "|2023-08-15|20750|21300|21400|20600|49.32| -0.02|Decreasing|      19600|\n",
      "|2023-08-14|21250|21200|21700|21050|44.64|  0.02|Increasing|   19781.25|\n",
      "|2023-08-11|20900|20850|20950|20050|39.74|  0.01|Increasing|   20056.25|\n",
      "|2023-08-10|20600|19900|21100|19900| 61.8|  0.04|Increasing|   20318.75|\n",
      "|2023-08-09|19900|20050|20300|19750|44.74| -0.02|Decreasing|   20493.75|\n",
      "|2023-08-08|20350|20500|20700|20050|44.21|  0.01|Increasing|   20631.25|\n",
      "|2023-08-07|20200|20300|20700|19800|44.45|  0.02|Increasing|      20575|\n",
      "|2023-08-04|19800|19550|19800|19050|79.62|  0.07|Increasing|   20468.75|\n",
      "|2023-08-03|18550|18350|18600|18050|42.86|  0.01|Increasing|   20193.75|\n",
      "|2023-08-02|18350|17750|18500|17700|43.28|  0.03|Increasing|   19831.25|\n",
      "|2023-08-01|17800|18850|18900|17800|53.14| -0.06|Decreasing|   19443.75|\n",
      "|2023-07-31|18850|18150|18850|17700|56.59|  0.03|Increasing|      19225|\n",
      "|2023-07-28|18350|17850|18900|17650|70.87|  0.03|Increasing|   19031.25|\n",
      "|2023-07-27|17850|17300|18150|17200|71.12|  0.04|Increasing|   18718.75|\n",
      "|2023-07-26|17200|16250|17200|16050|73.23|  0.06|Increasing|   18343.75|\n",
      "|2023-07-25|16200|16500|16900|16050|42.47|     0|Decreasing|   17893.75|\n",
      "|2023-07-24|16200|15400|16200|15400|95.94|  0.07|Increasing|      17600|\n",
      "|2023-07-21|15150|14800|15200|14700|34.69|  0.02|Increasing|      17200|\n",
      "|2023-07-20|14800|14700|14900|14600|16.99|  0.01|Increasing|      16825|\n",
      "|2023-07-19|14700|15100|15200|14650|34.69| -0.02|Decreasing|   16306.25|\n",
      "|2023-07-18|15050|15200|15250|14850|28.46| -0.02|Decreasing|   15893.75|\n",
      "|2023-07-17|15350|15300|15500|15100|36.93|  0.01|Increasing|   15581.25|\n",
      "|2023-07-14|15150|15050|15350|14900|43.04|  0.01|Increasing|      15325|\n",
      "|2023-07-13|14950|14700|15150|14600|30.51|  0.02|Increasing|   15168.75|\n",
      "|2023-07-12|14600|14800|14850|14450|21.67| -0.01|Decreasing|   14968.75|\n",
      "|2023-07-11|14700|15000|15050|14650|17.74| -0.01|Decreasing|    14912.5|\n",
      "|2023-07-10|14900|14600|15100|14500|27.53|  0.03|Increasing|      14925|\n",
      "|2023-07-07|14500|14250|14550|14250|19.48|  0.01|Increasing|      14900|\n",
      "|2023-07-06|14400|14700|14750|14200|23.89| -0.02|Decreasing|   14818.75|\n",
      "|2023-07-05|14700|15000|15100|14700|24.05| -0.01|Decreasing|    14737.5|\n",
      "|2023-07-04|14850|14550|14850|14350|23.18|  0.02|Increasing|      14700|\n",
      "|2023-07-03|14550|15000|15050|14500|30.11| -0.02|Decreasing|      14650|\n",
      "|2023-06-30|14850|15000|15250|14850|27.93| -0.01|Decreasing|   14681.25|\n",
      "|2023-06-29|15000|15800|15800|15000|39.22| -0.04|Decreasing|   14718.75|\n",
      "|2023-06-28|15600|15350|15850|15150|70.79|  0.04|Increasing|   14806.25|\n",
      "|2023-06-27|15000|15000|15350|14850|31.02|  0.01|Increasing|   14868.75|\n",
      "|2023-06-26|14900|14650|15200|14450|50.45|  0.03|Increasing|   14931.25|\n",
      "|2023-06-23|14500|14800|14850|14300|31.11| -0.01|Decreasing|   14906.25|\n",
      "|2023-06-22|14650|14550|15000|14500|29.99|  0.01|Increasing|   14881.25|\n",
      "|2023-06-21|14500|14600|14600|14250|28.74|     0|Decreasing|      14875|\n",
      "|2023-06-20|14500|14050|14550|14000|23.52|  0.04|Increasing|   14831.25|\n",
      "|2023-06-19|14000|14900|15000|14000|67.22| -0.06|Decreasing|   14706.25|\n",
      "|2023-06-16|14900|15450|15600|14800|51.56| -0.02|Decreasing|   14618.75|\n",
      "|2023-06-15|15250|15200|15450|15050|32.79|     0|Increasing|      14650|\n",
      "|2023-06-14|15200|15600|15850|15200| 38.8| -0.03|Decreasing|    14687.5|\n",
      "|2023-06-13|15600|14700|15600|14450|77.65|  0.07|Increasing|      14825|\n",
      "|2023-06-12|14600|14800|15000|14200|29.16|     0|Decreasing|   14818.75|\n",
      "|2023-06-09|14600|14250|14700|14150|30.83|  0.03|Increasing|   14831.25|\n",
      "|2023-06-08|14200|14800|15000|14200|35.67| -0.02|Decreasing|   14793.75|\n",
      "|2023-06-07|14550|13800|14550|13650|53.09|  0.07|Increasing|    14862.5|\n",
      "|2023-06-06|13600|13500|13650|13400|14.49|  0.01|Increasing|      14700|\n",
      "|2023-06-05|13500|14000|14050|13450|25.31| -0.03|Decreasing|   14481.25|\n",
      "|2023-06-02|13850|14100|14200|13750|24.19|     0|Decreasing|    14312.5|\n",
      "|2023-06-01|13900|13550|13950|13500|30.65|  0.03|Increasing|      14100|\n",
      "|2023-05-31|13500|13500|13800|13400|32.02|  0.01|Increasing|    13962.5|\n",
      "|2023-05-30|13350|13200|13600|13150|28.17|  0.02|Increasing|   13806.25|\n",
      "|2023-05-29|13050|13000|13250|12950|14.15|  0.01|Increasing|    13662.5|\n",
      "|2023-05-26|12950|13200|13250|12750|20.14| -0.02|Decreasing|    13462.5|\n",
      "|2023-05-25|13200|13250|13350|13150| NULL|     0|Decreasing|    13412.5|\n",
      "|2023-05-24|13250|13350|13650|13250|18.89|     0|Increasing|   13381.25|\n",
      "|2023-05-23|13200|13350|13450|13100|15.47| -0.01|Decreasing|      13300|\n",
      "|2023-05-22|13350|13400|13550|13250| 12.2|  0.01|Increasing|   13231.25|\n",
      "|2023-05-19|13200|13300|13350|13050|12.11| -0.01|Decreasing|   13193.75|\n",
      "|2023-05-18|13300|13350|13450|13200| NULL|     0|Decreasing|    13187.5|\n",
      "|2023-05-17|13300|13650|13700|13300|12.97| -0.03|Decreasing|   13218.75|\n",
      "|2023-05-16|13650|13550|13700|13400|10.89|  0.01|Increasing|   13306.25|\n",
      "|2023-05-15|13500|14000|14100|13500|17.13| -0.01|Decreasing|   13343.75|\n",
      "|2023-05-12|13700|13900|13950|13700|18.55| -0.01|Decreasing|      13400|\n",
      "|2023-05-11|13800|13450|13950|13450|20.59|  0.04|Increasing|      13475|\n",
      "+----------+-----+-----+-----+-----+-----+------+----------+-----------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the list of required columns\n",
    "columns = [\"Date\", \"Price\", \"Open\", \"High\", \"Low\", \"Vol\", \"Change\", \"direction\", \"mavg\"]\n",
    "\n",
    "# Rename columns to remove leading and trailing spaces\n",
    "for column in df.columns:\n",
    "    df = df.withColumnRenamed(column, column.strip())\n",
    "\n",
    "# Select the specified columns\n",
    "df = df.select(columns)\n",
    "\n",
    "# Show the first 100 rows\n",
    "df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "b27bee43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+------+----------+\n",
      "|High |round(Open, 0)|Change|direction |\n",
      "+-----+--------------+------+----------+\n",
      "|16150|15800.0       |-0.01 |Decreasing|\n",
      "|16050|15500.0       |0.02  |Increasing|\n",
      "|15500|15250.0       |0.02  |Increasing|\n",
      "|16500|15800.0       |-0.06 |Decreasing|\n",
      "|17600|17200.0       |-0.07 |Decreasing|\n",
      "|17800|17700.0       |-0.04 |Decreasing|\n",
      "|19150|18750.0       |-0.02 |Decreasing|\n",
      "|18500|17200.0       |0.07  |Increasing|\n",
      "|18450|18250.0       |-0.05 |Decreasing|\n",
      "|18900|18900.0       |-0.04 |Decreasing|\n",
      "+-----+--------------+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import round\n",
    "\n",
    "df.select(df.columns[3], round(df.columns[2]), df.columns[6], 'direction').show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec43709",
   "metadata": {},
   "source": [
    "# Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "fca1ccb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 334:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in 'Vol' column: 734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "#Calculate the missing values in a single column or in multiple columns by using\n",
    "#the built-in functions in PySpark, as follows\n",
    "missing_count = df.filter((df['Vol'] == '') | df['Vol'].isNull() | isnan(df['Vol'])).count()\n",
    "print(\"Number of missing values in 'Vol' column:\", missing_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "21bbb562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----+----+---+---+------+---------+----+\n",
      "|Date|Price|Open|High|Low|Vol|Change|direction|mavg|\n",
      "+----+-----+----+----+---+---+------+---------+----+\n",
      "|   0|    0|   0|   0|  0|734|     0|        0|   0|\n",
      "+----+-----+----+----+---+---+------+---------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Calculate all the missing values in the DataFrame,\n",
    "missing_counts = df.select([count(when((col(c) == '') | col(c).isNull() | isnan(col(c)), c)).alias(c) for c in df.columns])\n",
    "missing_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89be66eb",
   "metadata": {},
   "source": [
    "# One-Way Frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8987e5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "| direction|count|\n",
      "+----------+-----+\n",
      "|Increasing|  575|\n",
      "|Decreasing|  675|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(df['direction']).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b5f0ec",
   "metadata": {},
   "source": [
    "# Sorting and Filtering One-Way Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "8d1111b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+-----+------+----------+-----------+\n",
      "|      Date|Price| Open| High|  Low|  Vol|Change| direction|       mavg|\n",
      "+----------+-----+-----+-----+-----+-----+------+----------+-----------+\n",
      "|2023-09-29|15550|15800|16150|15550|12.38| -0.01|Decreasing|      15600|\n",
      "|2023-09-28|15750|15500|16050|15300|20.77|  0.02|Increasing|      15675|\n",
      "|2023-09-27|15500|15250|15500|14500| 30.5|  0.02|Increasing|15616.66667|\n",
      "|2023-09-26|15150|15800|16500|15150|33.77| -0.06|Decreasing|      15500|\n",
      "|2023-09-25|16200|17200|17600|16200|28.12| -0.07|Decreasing|      15640|\n",
      "|2023-09-22|17400|17700|17800|16950|36.48| -0.04|Decreasing|15933.33333|\n",
      "|2023-09-21|18200|18750|19150|18000|30.13| -0.02|Decreasing|16257.14286|\n",
      "|2023-09-20|18500|17200|18500|16600|40.16|  0.07|Increasing|    16537.5|\n",
      "|2023-09-19|17300|18250|18450|17050|54.72| -0.05|Decreasing|      16750|\n",
      "|2023-09-18|18150|18900|18900|18050|28.32| -0.04|Decreasing|      17050|\n",
      "|2023-09-15|18900|19000|19250|18650|26.73|  0.01|Increasing|      17475|\n",
      "|2023-09-14|18700|19600|19800|18600|76.98| -0.06|Decreasing|   17918.75|\n",
      "|2023-09-13|19950|21000|21100|19500|77.13| -0.05|Decreasing|    18387.5|\n",
      "|2023-09-12|20950|20150|20950|19650|57.21|  0.02|Increasing|   18831.25|\n",
      "|2023-09-11|20500|22050|22200|20500|71.69| -0.07|Decreasing|   19118.75|\n",
      "|2023-09-08|22000|21600|22250|21400|52.61|  0.02|Increasing|   19556.25|\n",
      "|2023-09-07|21600|22000|22150|21500|44.46| -0.01|Decreasing|   20093.75|\n",
      "|2023-09-06|21800|21300|21800|21000|46.22|  0.02|Increasing|      20550|\n",
      "|2023-09-05|21400|20900|21700|20800|53.91|  0.05|Increasing|    20862.5|\n",
      "|2023-08-31|20450|20100|20500|20000|36.64|  0.02|Increasing|   21081.25|\n",
      "+----------+-----+-----+-----+-----+-----+------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Subsetting and creating a temporary DataFrame to eliminate any missing values\n",
    "df_temp=df.filter((df['mavg']!='')&(df['mavg'].isNotNull()) &\n",
    "(~isnan(df['mavg'])))\n",
    "df_temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "e66b5482",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----------+----------+------------+\n",
      "|      Date| Open|Price|  Vol|       mavg| direction|Rounded_Open|\n",
      "+----------+-----+-----+-----+-----------+----------+------------+\n",
      "|2023-09-29|15800|15550|12.38|      15600|Decreasing|     15800.0|\n",
      "|2023-09-28|15500|15750|20.77|      15675|Increasing|     15500.0|\n",
      "|2023-09-27|15250|15500| 30.5|15616.66667|Increasing|     15250.0|\n",
      "|2023-09-26|15800|15150|33.77|      15500|Decreasing|     15800.0|\n",
      "|2023-09-25|17200|16200|28.12|      15640|Decreasing|     17200.0|\n",
      "|2023-09-22|17700|17400|36.48|15933.33333|Decreasing|     17700.0|\n",
      "|2023-09-21|18750|18200|30.13|16257.14286|Decreasing|     18750.0|\n",
      "|2023-09-20|17200|18500|40.16|    16537.5|Increasing|     17200.0|\n",
      "|2023-09-19|18250|17300|54.72|      16750|Decreasing|     18250.0|\n",
      "|2023-09-18|18900|18150|28.32|      17050|Decreasing|     18900.0|\n",
      "|2023-09-15|19000|18900|26.73|      17475|Increasing|     19000.0|\n",
      "|2023-09-14|19600|18700|76.98|   17918.75|Decreasing|     19600.0|\n",
      "|2023-09-13|21000|19950|77.13|    18387.5|Decreasing|     21000.0|\n",
      "|2023-09-12|20150|20950|57.21|   18831.25|Increasing|     20150.0|\n",
      "|2023-09-11|22050|20500|71.69|   19118.75|Decreasing|     22050.0|\n",
      "|2023-09-08|21600|22000|52.61|   19556.25|Increasing|     21600.0|\n",
      "|2023-09-07|22000|21600|44.46|   20093.75|Decreasing|     22000.0|\n",
      "|2023-09-06|21300|21800|46.22|      20550|Increasing|     21300.0|\n",
      "|2023-09-05|20900|21400|53.91|    20862.5|Increasing|     20900.0|\n",
      "|2023-08-31|20100|20450|36.64|   21081.25|Increasing|     20100.0|\n",
      "+----------+-----+-----+-----+-----------+----------+------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------------+-----+\n",
      "|Rounded_Open|count|\n",
      "+------------+-----+\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Subsetting the DataFrame to Open that are repeated more than 20 times\n",
    "columns=[\"Date\",\"Open\",\"Price\",\"Vol\",\"mavg\",\"direction\"]\n",
    "df_temp = df.select(columns)\n",
    "df_temp=df_temp.withColumn(\"Rounded_Open\", round(col(\"Open\"), 0))\n",
    "df_temp.show()\n",
    "df_temp.groupby(df_temp['Rounded_Open'])\\\n",
    ".count().filter(\"`count` >20\")\\\n",
    ".sort(col(\"count\").desc()).show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e068ac",
   "metadata": {},
   "source": [
    "# Casting Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "990f82b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+-----+-----+-----+------+----------+-----------+\n",
      "|      Date|Price| Open| High|  Low|  Vol|Change| direction|       mavg|\n",
      "+----------+-----+-----+-----+-----+-----+------+----------+-----------+\n",
      "|2023-09-29|15550|15800|16150|15550|12.38| -0.01|Decreasing|      15600|\n",
      "|2023-09-28|15750|15500|16050|15300|20.77|  0.02|Increasing|      15675|\n",
      "|2023-09-27|15500|15250|15500|14500| 30.5|  0.02|Increasing|15616.66667|\n",
      "|2023-09-26|15150|15800|16500|15150|33.77| -0.06|Decreasing|      15500|\n",
      "|2023-09-25|16200|17200|17600|16200|28.12| -0.07|Decreasing|      15640|\n",
      "|2023-09-22|17400|17700|17800|16950|36.48| -0.04|Decreasing|15933.33333|\n",
      "|2023-09-21|18200|18750|19150|18000|30.13| -0.02|Decreasing|16257.14286|\n",
      "|2023-09-20|18500|17200|18500|16600|40.16|  0.07|Increasing|    16537.5|\n",
      "|2023-09-19|17300|18250|18450|17050|54.72| -0.05|Decreasing|      16750|\n",
      "|2023-09-18|18150|18900|18900|18050|28.32| -0.04|Decreasing|      17050|\n",
      "|2023-09-15|18900|19000|19250|18650|26.73|  0.01|Increasing|      17475|\n",
      "|2023-09-14|18700|19600|19800|18600|76.98| -0.06|Decreasing|   17918.75|\n",
      "|2023-09-13|19950|21000|21100|19500|77.13| -0.05|Decreasing|    18387.5|\n",
      "|2023-09-12|20950|20150|20950|19650|57.21|  0.02|Increasing|   18831.25|\n",
      "|2023-09-11|20500|22050|22200|20500|71.69| -0.07|Decreasing|   19118.75|\n",
      "|2023-09-08|22000|21600|22250|21400|52.61|  0.02|Increasing|   19556.25|\n",
      "|2023-09-07|21600|22000|22150|21500|44.46| -0.01|Decreasing|   20093.75|\n",
      "|2023-09-06|21800|21300|21800|21000|46.22|  0.02|Increasing|      20550|\n",
      "|2023-09-05|21400|20900|21700|20800|53.91|  0.05|Increasing|    20862.5|\n",
      "|2023-08-31|20450|20100|20500|20000|36.64|  0.02|Increasing|   21081.25|\n",
      "+----------+-----+-----+-----+-----+-----+------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Casting\n",
    "df = df.withColumn('Vol',df['Vol'].cast(\"float\"))\n",
    "#After Casting\n",
    "df.dtypes\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "b45d86de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Date', 'date'),\n",
       " ('Price', 'float'),\n",
       " ('Open', 'float'),\n",
       " ('High', 'string'),\n",
       " ('Low', 'string'),\n",
       " ('Vol', 'float'),\n",
       " ('Change', 'string'),\n",
       " ('direction', 'string'),\n",
       " ('mavg', 'float')]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing necessary libraries\n",
    "from pyspark.sql.types import *\n",
    "#Identifying and assigning lists of variables\n",
    "float_vars=['Open', 'Price', 'Vol','mavg']\n",
    "date_vars=['Date']\n",
    "#Converting variables\n",
    "for column in float_vars:\n",
    " df=df.withColumn(column,df[column].cast(FloatType()))\n",
    "for column in date_vars:\n",
    " df=df.withColumn(column,df[column].cast(DateType()))\n",
    "\n",
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "edf525f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+-----+-----+-----+------+----------+---------+\n",
      "|Date      |Price  |Open   |High |Low  |Vol  |Change|direction |mavg     |\n",
      "+----------+-------+-------+-----+-----+-----+------+----------+---------+\n",
      "|2023-09-29|15550.0|15800.0|16150|15550|12.38|-0.01 |Decreasing|15600.0  |\n",
      "|2023-09-28|15750.0|15500.0|16050|15300|20.77|0.02  |Increasing|15675.0  |\n",
      "|2023-09-27|15500.0|15250.0|15500|14500|30.5 |0.02  |Increasing|15616.667|\n",
      "|2023-09-26|15150.0|15800.0|16500|15150|33.77|-0.06 |Decreasing|15500.0  |\n",
      "|2023-09-25|16200.0|17200.0|17600|16200|28.12|-0.07 |Decreasing|15640.0  |\n",
      "|2023-09-22|17400.0|17700.0|17800|16950|36.48|-0.04 |Decreasing|15933.333|\n",
      "|2023-09-21|18200.0|18750.0|19150|18000|30.13|-0.02 |Decreasing|16257.143|\n",
      "|2023-09-20|18500.0|17200.0|18500|16600|40.16|0.07  |Increasing|16537.5  |\n",
      "|2023-09-19|17300.0|18250.0|18450|17050|54.72|-0.05 |Decreasing|16750.0  |\n",
      "|2023-09-18|18150.0|18900.0|18900|18050|28.32|-0.04 |Decreasing|17050.0  |\n",
      "+----------+-------+-------+-----+-----+-----+------+----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba4cbfe",
   "metadata": {},
   "source": [
    "# Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "fa3f7a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+\n",
      "|summary|              Open|             Price|               Vol|\n",
      "+-------+------------------+------------------+------------------+\n",
      "|  count|              1250|              1250|               516|\n",
      "|   mean|        45396.5776|        45415.5504|408.38207434314165|\n",
      "| stddev|24421.615683645086|24423.318754605192| 341.4620800104249|\n",
      "|    min|           10250.0|           10250.0|              10.0|\n",
      "|    max|           93969.0|           92366.0|             997.2|\n",
      "+-------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns=[\"Open\",\"Price\",\"Vol\"]\n",
    "# Subsetting the required columns from the DataFrame\n",
    "df = df.select(columns)\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "edf3e2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median of Open is [33490.0]\n"
     ]
    }
   ],
   "source": [
    "#Since unknown values in Open are marked to be 0, let’s filter out those\n",
    "#values before calculating the median\n",
    "df_temp = df.filter((df['Open']!=0)&(df['Open'].isNotNull()) &\n",
    "(~isnan(df['Open'])))\n",
    "#Here the second parameter indicates the median value, which is 0.5; you\n",
    "#can also try adjusting the value to calculate other percentiles\n",
    "median=df.approxQuantile('Open',[0.5],0.1)\n",
    "#Printing the Value\n",
    "print ('The median of Open is '+str(median))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dfb3fe",
   "metadata": {},
   "source": [
    "# Unique/Distinct Values and Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "ee7e51fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 393:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Count|\n",
      "+-----+\n",
      "|    2|\n",
      "+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#You may sometimes just want to know the number of levels (cardinality) within\n",
    "#a variable. You can do this using the countDistinct function available in Spark\n",
    "# Counts the distinct occurances of titles\n",
    "full_df.agg(countDistinct(col(\"Direction\")).alias(\"Count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "bc20940c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 397:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|Date      |\n",
      "+----------+\n",
      "|2023-05-18|\n",
      "|2022-10-05|\n",
      "|2021-11-03|\n",
      "|2020-04-13|\n",
      "|2020-02-26|\n",
      "|2019-08-23|\n",
      "|2019-08-22|\n",
      "|2019-08-08|\n",
      "|2023-04-28|\n",
      "|2023-04-21|\n",
      "+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Counts the distinct occurances of Date\n",
    "full_df.select('Date').distinct().show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6e32e9",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "00feb4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 400:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+-------------+\n",
      "|Open   |Price  |Vol  |newcat       |\n",
      "+-------+-------+-----+-------------+\n",
      "|15800.0|15550.0|12.38|{Small, High}|\n",
      "|15500.0|15750.0|20.77|{Small, High}|\n",
      "|15250.0|15500.0|30.5 |{Small, High}|\n",
      "+-------+-------+-----+-------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Now, let’s find out the dates that do not end with an \"17\"\n",
    "df_temp.filter(~col('Date').like('%17')).show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "2a712cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92366.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250\n",
      "45415.5504\n"
     ]
    }
   ],
   "source": [
    "#So, let’s first calculate the max by using the following command. The agg function\n",
    "#used here is handy instead of using describe when you are looking for a specific statistic:\n",
    "max_pop=df.agg({'Price': 'max'}).collect()[0]['max(Price)']\n",
    "print(max_pop)\n",
    "count_obs= df.count()\n",
    "print(count_obs)\n",
    "mean_pop=df.agg({'Price': 'mean'}).collect()[0]['avg(Price)']\n",
    "print(mean_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "9d01b302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745026625237.3237\n",
      "596498498.9890503\n"
     ]
    }
   ],
   "source": [
    "#The lit function is a way\n",
    "#to interact with column literals. It is very useful when you want \n",
    "#to create a column with a value directly.\n",
    "df=df.withColumn('mean_Price',lit(mean_pop))\n",
    "df=df.withColumn('varaiance',pow((df['Price']-df['mean_Price']),2))\n",
    "variance_sum=df.agg({'varaiance': 'sum'}).collect()[0]['sum(varaiance)']\n",
    "print(variance_sum)\n",
    "variance_population= variance_sum/(count_obs-1)\n",
    "print(variance_population)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aff635",
   "metadata": {},
   "source": [
    "# Creating new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "6248431b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+-------------+\n",
      "|   Open|  Price|  Vol|       newcat|\n",
      "+-------+-------+-----+-------------+\n",
      "|15800.0|15550.0|12.38|{Small, High}|\n",
      "|15500.0|15750.0|20.77|{Small, High}|\n",
      "|15250.0|15500.0| 30.5|{Small, High}|\n",
      "|15800.0|15150.0|33.77|{Small, High}|\n",
      "|17200.0|16200.0|28.12|{Small, High}|\n",
      "|17700.0|17400.0|36.48|{Small, High}|\n",
      "|18750.0|18200.0|30.13|{Small, High}|\n",
      "|17200.0|18500.0|40.16|{Small, High}|\n",
      "|18250.0|17300.0|54.72|{Small, High}|\n",
      "|18900.0|18150.0|28.32|{Small, High}|\n",
      "+-------+-------+-----+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def new_cols(Vol,Open):\n",
    " if Vol<408: Volume_cat='Small'\n",
    " elif Vol<508: Volume_cat='Medium'\n",
    " else: Volume_cat='Big'\n",
    " if Open<3: Open_cat='Low'\n",
    " elif Open<5: Open_cat='Mid'\n",
    " else: Open_cat='High'\n",
    " return Volume_cat,Open_cat\n",
    "# Apply the user-defined function on the DataFrame\n",
    "udfB=udf(new_cols,StructType([StructField(\"Volume_cat\", StringType(),\n",
    "True),StructField(\"Open_cat\", StringType(), True)]))\n",
    "# Pass a user-defined function with two input columns Open and Close\n",
    "df_temp=df.select('Open','Price','Vol').withColumn(\"newcat\",udfB(\"Vol\",\"Open\"))\n",
    "df_temp.show(10)                                                                   \n",
    "                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "c1b74afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+----------+--------+\n",
      "|Open   |Price  |Vol  |Volume_cat|Open_cat|\n",
      "+-------+-------+-----+----------+--------+\n",
      "|15800.0|15550.0|12.38|Small     |High    |\n",
      "|15500.0|15750.0|20.77|Small     |High    |\n",
      "|15250.0|15500.0|30.5 |Small     |High    |\n",
      "|15800.0|15150.0|33.77|Small     |High    |\n",
      "|17200.0|16200.0|28.12|Small     |High    |\n",
      "|17700.0|17400.0|36.48|Small     |High    |\n",
      "|18750.0|18200.0|30.13|Small     |High    |\n",
      "|17200.0|18500.0|40.16|Small     |High    |\n",
      "|18250.0|17300.0|54.72|Small     |High    |\n",
      "|18900.0|18150.0|28.32|Small     |High    |\n",
      "+-------+-------+-----+----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 414:>                                                        (0 + 1) / 1]\r\n",
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Unbundle the struct type columns into individual columns and drop the struct type\n",
    "df_with_newcols = df_temp.select('Open','Price','Vol','newcat')\\\n",
    ".withColumn('Volume_cat', df_temp.newcat\\\n",
    ".getItem('Volume_cat'))\\\n",
    ".withColumn('Open_cat', df_temp.newcat\\\n",
    ".getItem('Open_cat')).drop('newcat')\n",
    "df_with_newcols.show(10,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d215cdf",
   "metadata": {},
   "source": [
    "Another way we can achieve the same result is through the when function. One\n",
    "advantage of using this function is you don’t have to define the output data type. This\n",
    "is handy for quick and dirty operations. Let’s recreate the preceding columns using the\n",
    "when function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "b2736cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----+----------+--------+\n",
      "|   Open|  Price|  Vol|Volume_cat|Open_cat|\n",
      "+-------+-------+-----+----------+--------+\n",
      "|15800.0|15550.0|12.38|     Small|     Low|\n",
      "|15500.0|15750.0|20.77|     Small|     Low|\n",
      "|15250.0|15500.0| 30.5|     Small|     Low|\n",
      "|15800.0|15150.0|33.77|     Small|     Low|\n",
      "|17200.0|16200.0|28.12|     Small|     Low|\n",
      "|17700.0|17400.0|36.48|     Small|     Low|\n",
      "|18750.0|18200.0|30.13|     Small|     Low|\n",
      "|17200.0|18500.0|40.16|     Small|     Low|\n",
      "|18250.0|17300.0|54.72|     Small|     Low|\n",
      "|18900.0|18150.0|28.32|     Small|     Low|\n",
      "+-------+-------+-----+----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# def new_cols(Volume,Open):\n",
    "#  if Volume<48948400: Volume_cat='Small'\n",
    "#  elif Volume<58948400: Volume_cat='Medium'\n",
    "#  else: Volume_cat='Big'\n",
    "#  if Open<3: Open_cat='Low'\n",
    "#  elif Open<5: Open_cat='Mid'\n",
    "#  else: Open_cat='High'\n",
    "#  return Volume_cat,Open_cat\n",
    "# In order to comment on multiple lines at once in Jupyter Notebook, \n",
    "# you have to select the required lines and then press the Ctrl + /\n",
    "df_with_newcols = df_temp.select('Open','Price','Vol').\\\n",
    "withColumn('Volume_cat', when(df_temp['Vol']<408,'Small').\\\n",
    "when(df_temp['Vol']<508,'Medium').otherwise('Big')).\\\n",
    "withColumn('Open_cat', when(df_temp['Open']<45000,'Low').\n",
    "when(df_temp['Open']<50000,'Mid').otherwise('High'))\n",
    "df_with_newcols.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346700f8",
   "metadata": {},
   "source": [
    "# Deleting and Renaming Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "9e9aab24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----------+--------+\n",
      "|   Open|  Vol|Volume_cat|Open_cat|\n",
      "+-------+-----+----------+--------+\n",
      "|15800.0|12.38|     Small|     Low|\n",
      "|15500.0|20.77|     Small|     Low|\n",
      "|15250.0| 30.5|     Small|     Low|\n",
      "|15800.0|33.77|     Small|     Low|\n",
      "|17200.0|28.12|     Small|     Low|\n",
      "|17700.0|36.48|     Small|     Low|\n",
      "|18750.0|30.13|     Small|     Low|\n",
      "|17200.0|40.16|     Small|     Low|\n",
      "|18250.0|54.72|     Small|     Low|\n",
      "|18900.0|28.32|     Small|     Low|\n",
      "+-------+-----+----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the drop function. to drop any column or columns \n",
    "columns_to_drop=['Price']\n",
    "df_with_newcols=df_with_newcols.drop(*columns_to_drop)\n",
    "df_with_newcols.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "8f2c37da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+----------+--------+\n",
      "|Renamed_Open|Renamed_Volume|Volume_cat|Open_cat|\n",
      "+------------+--------------+----------+--------+\n",
      "|     15800.0|         12.38|     Small|     Low|\n",
      "|     15500.0|         20.77|     Small|     Low|\n",
      "|     15250.0|          30.5|     Small|     Low|\n",
      "|     15800.0|         33.77|     Small|     Low|\n",
      "|     17200.0|         28.12|     Small|     Low|\n",
      "|     17700.0|         36.48|     Small|     Low|\n",
      "|     18750.0|         30.13|     Small|     Low|\n",
      "|     17200.0|         40.16|     Small|     Low|\n",
      "|     18250.0|         54.72|     Small|     Low|\n",
      "|     18900.0|         28.32|     Small|     Low|\n",
      "+------------+--------------+----------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renaming can be done using \n",
    "# either the withColumnRenamed function or the alias function.\n",
    "df_with_newcols = df_with_newcols\\\n",
    ".withColumnRenamed('Open','Renamed_Open')\\\n",
    ".withColumnRenamed('Vol','Renamed_Volume')\n",
    "df_with_newcols.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "e76b13e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|Volume_cat1|Open_cat1|\n",
      "+-----------+---------+\n",
      "|      Small|      Low|\n",
      "|      Small|      Low|\n",
      "|      Small|      Low|\n",
      "|      Small|      Low|\n",
      "|      Small|      Low|\n",
      "|      Small|      Low|\n",
      "|      Small|      Low|\n",
      "|      Small|      Low|\n",
      "|      Small|      Low|\n",
      "|      Small|      Low|\n",
      "+-----------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To change multiple column names,try the following command:\n",
    "# Define all the variable changes in the list\n",
    "new_names = [('Volume_cat','Volume_cat1'),('Open_cat','Open_cat1')]\n",
    "# Applying the alias function\n",
    "df_with_newcols_renamed = df_with_newcols\\\n",
    ".select(list(map(lambda old,new:col(old).alias(new),*zip(*new_names))))\n",
    "df_with_newcols_renamed.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4137785e",
   "metadata": {},
   "source": [
    "# 5.2 Utility Functions and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "cb316c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+----------+--------+---------------+\n",
      "|Renamed_Open|Renamed_Volume|Volume_cat|Open_cat|Open_Volume_Cat|\n",
      "+------------+--------------+----------+--------+---------------+\n",
      "|     15800.0|         12.38|     Small|     Low|       SmallLow|\n",
      "|     15500.0|         20.77|     Small|     Low|       SmallLow|\n",
      "|     15250.0|          30.5|     Small|     Low|       SmallLow|\n",
      "|     15800.0|         33.77|     Small|     Low|       SmallLow|\n",
      "|     17200.0|         28.12|     Small|     Low|       SmallLow|\n",
      "|     17700.0|         36.48|     Small|     Low|       SmallLow|\n",
      "|     18750.0|         30.13|     Small|     Low|       SmallLow|\n",
      "|     17200.0|         40.16|     Small|     Low|       SmallLow|\n",
      "|     18250.0|         54.72|     Small|     Low|       SmallLow|\n",
      "|     18900.0|         28.32|     Small|     Low|       SmallLow|\n",
      "+------------+--------------+----------+--------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To concatenate the values of budget_cat and ratings together into a\n",
    "# single column, we can do so using the concat function. On top of this, let’s change the\n",
    "# case of the new column to lowercase and trim away any white spaces using the lower\n",
    "# and trim functions\n",
    "# Concatenating two variables\n",
    "df_with_newcols=df_with_newcols.\\\n",
    "withColumn('Open_Volume_Cat',concat(df_with_newcols.\\\n",
    "Volume_cat,df_with_newcols.Open_cat))\n",
    "df_with_newcols.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf423ba",
   "metadata": {},
   "source": [
    "# Registering DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "f0e2f8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 420:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|Volume_cat|count(Volume_cat)|\n",
      "+----------+-----------------+\n",
      "|    Medium|               40|\n",
      "|     Small|              239|\n",
      "|       Big|              971|\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Registering temporary table\n",
    "df_with_newcols.registerTempTable('temp_data')\n",
    "# Applying the function to show the results\n",
    "spark.sql('select Volume_cat, count(Volume_cat)\\\n",
    "from temp_data group by Volume_cat').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39c7a2e",
   "metadata": {},
   "source": [
    "# Window Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "dd3564da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the window functions\n",
    "from pyspark.sql.window import *\n",
    "# Step 1: Filtering the missing values\n",
    "df_with_newcols=df_with_newcols.filter( (df_with_newcols['Renamed_Open'].\n",
    "isNotNull()) & (~isnan(df_with_newcols['Renamed_Open'])) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "b72d540f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 17:25:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/10/02 17:25:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/10/02 17:25:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/10/02 17:25:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/10/02 17:25:40 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+----------+-----------+\n",
      "|Renamed_Open|Renamed_Volume|Volume_cat|decile_rank|\n",
      "+------------+--------------+----------+-----------+\n",
      "|     32544.0|         997.2|       Big|          1|\n",
      "|     31709.0|         997.2|       Big|          1|\n",
      "|     32822.0|         994.6|       Big|          1|\n",
      "|     33656.0|         985.1|       Big|          1|\n",
      "|     33100.0|         982.8|       Big|          1|\n",
      "|     38552.0|         977.7|       Big|          1|\n",
      "|     32544.0|         974.4|       Big|          1|\n",
      "|     36994.0|         974.2|       Big|          1|\n",
      "|     32544.0|         968.3|       Big|          1|\n",
      "|     74000.0|         967.4|       Big|          1|\n",
      "+------------+--------------+----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Applying the window functions for calculating deciles\n",
    "df_with_newcols = df_with_newcols.select(\"Renamed_Open\",\"Renamed_Volume\",\"Volume_cat\",\n",
    "ntile(10).over(Window.partitionBy().orderBy(df_with_newcols['Renamed_Volume'].\n",
    "desc())).alias(\"decile_rank\"))\n",
    "df_with_newcols.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "b0e87cfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/02 17:25:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/10/02 17:25:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/10/02 17:25:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/10/02 17:25:41 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+---------------------+\n",
      "|decile_rank|min_Volume|max_Volume|count(Renamed_Volume)|\n",
      "+-----------+----------+----------+---------------------+\n",
      "|          1|     742.0|     997.2|                  125|\n",
      "|          2|     482.5|     741.3|                  125|\n",
      "|          3|     34.69|     479.6|                  125|\n",
      "|          4|     11.46|     34.31|                  125|\n",
      "|          5|      10.0|     11.37|                   16|\n",
      "|          6|      NULL|      NULL|                    0|\n",
      "|          7|      NULL|      NULL|                    0|\n",
      "|          8|      NULL|      NULL|                    0|\n",
      "|          9|      NULL|      NULL|                    0|\n",
      "|         10|      NULL|      NULL|                    0|\n",
      "+-----------+----------+----------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3:Dispalying the values\n",
    "df_with_newcols.groupby(\"decile_rank\")\\\n",
    ".agg(min('Renamed_Volume').alias('min_Volume'),max('Renamed_Volume')\\\n",
    ".alias('max_Volume'),count('Renamed_Volume')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cee82c",
   "metadata": {},
   "source": [
    "# Other Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba344037",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.show(200)\n",
    "columns=[\"Date\",\"Open\",\"Close\",\"Volume\",\"direction\"]\n",
    "df_temp=full_df.select(columns)\n",
    "df_temp=df_temp.withColumn('Year',year('Date'))\n",
    "df_temp.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33666ca2",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e73d3c",
   "metadata": {},
   "source": [
    "The first\n",
    "parameter True/False indicates whether you would like to do a sample with or without\n",
    "replacement. Here, we would like to do it without replacement, so we selected False.\n",
    "The second parameter is the fraction. It indicates the proportion of the population you\n",
    "would like to have in the sample. The third parameter is the seed, which guarantees you\n",
    "the same result when you run this snippet every single time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "aa56e30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple random sampling in PySpark with replacement\n",
    "df_sample = df.sample(False, 0.4, 11)\n",
    "df_sample.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bc6360",
   "metadata": {},
   "source": [
    "# Pandas Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "8f58a552",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "[Stage 434:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+----------+-------------------+\n",
      "|   Open|  Price|               Vol|mean_Price|          varaiance|\n",
      "+-------+-------+------------------+----------+-------------------+\n",
      "|15800.0|15550.0|12.380000114440918|45415.5504|8.919511006949402E8|\n",
      "|15500.0|15750.0|20.770000457763672|45415.5504|8.800448805349401E8|\n",
      "|15250.0|15500.0|              30.5|45415.5504|8.949401557349402E8|\n",
      "|15800.0|15150.0| 33.77000045776367|45415.5504|9.160035410149401E8|\n",
      "|17200.0|16200.0|  28.1200008392334|45415.5504|8.535483851749401E8|\n",
      "+-------+-------+------------------+----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Pandas to PySpark\n",
    "df_pandas=df.toPandas()\n",
    "# Pandas to PySpark\n",
    "df_py = spark.createDataFrame(df_pandas)\n",
    "df_py.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
